{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PROJECT_ROOT_PATH = '../../..'\n",
    "TEMP_PATH = PROJECT_ROOT_PATH + '/tmp'\n",
    "MODEL_PATH = TEMP_PATH + '/model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SUGGEST_DATA_PATH = TEMP_PATH + '/suggestion.top.10.txt'\n",
    "OCR_ERROR_PATH = PROJECT_ROOT_PATH + '/data/error.gt.tsv'\n",
    "SUFFIX = 'top3'\n",
    "\n",
    "TRAIN_SPLITS_RATIO = 0.8\n",
    "TEST_SPLITS_RATIO  = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "from sklc import data\n",
    "from sklc import model\n",
    "from sklearn import feature_selection\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def data_split(data_path, gt_path, train_ratio, test_ratio):\n",
    "    \"\"\" Split data by the position of the original text at the given ratio.\n",
    "    \"\"\"\n",
    "    if train_ratio + test_ratio != 1.0:\n",
    "        raise ValueError\n",
    "\n",
    "    # Get the split positions according to the ratios.\n",
    "    poss = [int(l.split('\\t')[0]) for l in codecs.open(gt_path, 'r', 'utf-8')]\n",
    "    spos = poss[int(len(poss) * train_ratio)]\n",
    "\n",
    "    # Splits data according to the ratios.\n",
    "    dataset = data.Dataset.read(DATA_PATH)\n",
    "    return dataset.subset(filt=lambda e: e.position < spos,\n",
    "            return_complement=True), dataset\n",
    "\n",
    "\n",
    "def data_preproc():\n",
    "    \"\"\" Preprocess the data for detection purpose.\n",
    "    \"\"\"\n",
    "    # Process test\n",
    "    def parse(line):\n",
    "        \"\"\" Get the range of each error. \"\"\"\n",
    "        sp = line.strip().split('\\t')\n",
    "        str_pos = int(sp[0])\n",
    "        end_pos = str_pos + len(sp[1])\n",
    "        return (str_pos, end_pos)\n",
    "    errs = [parse(l) for l in codecs.open(GT_PATH, 'r', 'utf-8')]\n",
    "\n",
    "    def candidate_preproc():\n",
    "\n",
    "\n",
    "def main():\n",
    "    (train_data, test_data), total_data = data_split(DATA_PATH, GT_PATH,\n",
    "            TRAIN_SPLITS_RATIO, TEST_SPLITS_RATIO)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    for md, (_override, _weighted, _path, _grid, _estimator) in TRAIN_SETTINGS:\n",
    "        try:\n",
    "            if md == model.SKLModel:\n",
    "                md(_estimator, _grid, train_data, override=_override,\n",
    "                        weighted=_weighted, pkl_path=_path)\n",
    "            elif _grid != None:\n",
    "                md(train_data, override=_override, weighted=_weighted,\n",
    "                        pkl_path=_path, para_grid=_grid)\n",
    "            else:\n",
    "                md(train_data, override=_override, weighted=_weighted,\n",
    "                        pkl_path=_path)\n",
    "        except Exception as e:\n",
    "            #print('Error')\n",
    "            #print(str(e))\n",
    "            #print()\n",
    "            #sys.exit(1)\n",
    "            pass # skip error model\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    for md, (_override, _weighted, _path, _grid, _estimator) in \\\n",
    "            TRAIN_SETTINGS[5:9] + [TRAIN_SETTINGS[10]]:\n",
    "        print(md)\n",
    "        \n",
    "        try:\n",
    "            lm = md(_estimator, _grid, train_data, pkl_path=_path) if md == model.SKLModel else md(train_data, pkl_path=_path)\n",
    "            lm.predict(test_data)\n",
    "            print('1: {}\\n3: {}\\n5: {}\\n10: {}\\nA: {}\\n'\n",
    "                .format(test_data.precision_at(1),\n",
    "                      test_data.precision_at(1),\n",
    "                      test_data.precision_at(3),\n",
    "                      test_data.precision_at(5),\n",
    "                      test_data.precision_at(10),\n",
    "                      test_data.precision_at()))\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "            pass\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
