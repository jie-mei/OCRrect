{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Resource Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PROJECT_ROOT_PATH = '../../../..'\n",
    "TEMP_PATH = PROJECT_ROOT_PATH + '/tmp'\n",
    "DATA_PATH  = TEMP_PATH + '/detect/data'\n",
    "MODEL_PATH = TEMP_PATH + '/detect/model'\n",
    "\n",
    "WORDS_TRAIN_PATH = DATA_PATH + '/words.train.tsv'\n",
    "WORDS_TEST_PATH  = DATA_PATH + '/words.test.tsv'\n",
    "OUT_WORDS_TRAIN_PATH = DATA_PATH + '/words.train.fix.tsv'\n",
    "OUT_WORDS_TEST_PATH  = DATA_PATH + '/words.test.fix.tsv'\n",
    "\n",
    "MIBIO_PATH = PROJECT_ROOT_PATH + '/ocrrect-experiment/src/main/resources/mibio-ocr'\n",
    "OCR_TEXT_PATH = MIBIO_PATH + '/ocr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "OCR_TEXT = ''.join([open(path, 'r').read() for path in glob.glob(OCR_TEXT_PATH + '/*')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407369\n"
     ]
    }
   ],
   "source": [
    "def _read_words(path):\n",
    "    words = []\n",
    "    with open(path, 'r') as word_file:\n",
    "        for line in word_file:\n",
    "            line = line.rstrip()\n",
    "            _, _, _, _, word, _, _, _, pos = line.split('\\t')\n",
    "            words.append((word, pos))\n",
    "    return words\n",
    "            \n",
    "# Print out the number of training words before ad-hoc modification.\n",
    "SPLIT_POS = int(_read_words(WORDS_TRAIN_PATH)[-1][1])\n",
    "print(SPLIT_POS)\n",
    "\n",
    "UNALIGNED_WORDS = []\n",
    "UNALIGNED_WORDS.extend(_read_words(WORDS_TRAIN_PATH))\n",
    "UNALIGNED_WORDS.extend(_read_words(WORDS_TEST_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ad-hoc modification on words.\n",
    "UNALIGNED_WORDS.insert(12222, ('\\'s', -1))\n",
    "UNALIGNED_WORDS.insert(40541, ('\\'s', -2))\n",
    "UNALIGNED_WORDS.insert(44896, ('\\'s', -3))\n",
    "UNALIGNED_WORDS.insert(66548, ('\\'s', -4))\n",
    "UNALIGNED_WORDS.insert(89249, ('\\'s', -5))\n",
    "UNALIGNED_WORDS.insert(99066, ('\\'s', -5))\n",
    "UNALIGNED_WORDS.append(('Sussex', -6))\n",
    "UNALIGNED_WORDS.append(('.', -7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Tokenization Alignment\n",
    "\n",
    "Align the tokens to the original OCR content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def _match(c1, c2):\n",
    "    return ord(c1) == ord(c2)\n",
    "\n",
    "def align(text, unaligned_words):\n",
    "    aligned_words = []\n",
    "    tpos = 0\n",
    "    for widx, (word, pos) in enumerate(unaligned_words):\n",
    "        for wpos in range(len(word)):\n",
    "            while text[tpos].isspace():\n",
    "                tpos += 1\n",
    "            if not _match(word[wpos], text[tpos]):\n",
    "                # One observed bug is tokenization accidentially drops `'s` token. Thus we detect if the upcoming token is missing.\n",
    "                mo = re.match(r'(\\'s *)(.)', text[tpos:tpos + 10])\n",
    "                if mo and _match(word[wpos], mo.group(2)):\n",
    "                    aligned_words.append(('\\'s', tpos))\n",
    "                    tpos += len(mo.group(1))\n",
    "                    aligned_words.append((word, tpos))\n",
    "                elif text[tpos:tpos + 2] == '-\\n' and ord(word[wpos]) == ord(text[tpos + 2]):\n",
    "                    tpos += 2\n",
    "                else:\n",
    "                    raise ValueError('Character mismatched: (%d) %s, (%d) %s\\nat %d:  %s\\nand: %s'\n",
    "                                     % (ord(word[wpos]), word[wpos + 1: wpos + 5],\n",
    "                                        ord(text[tpos]), text[tpos + 1: tpos + 5],\n",
    "                                        widx, str(unaligned_words[widx - 2: widx + 3]),\n",
    "                                        text[tpos - 10: tpos + 10]\n",
    "                                       ))\n",
    "            elif not wpos:\n",
    "                aligned_words.append((word, tpos))\n",
    "            tpos += 1\n",
    "    return aligned_words\n",
    "\n",
    "ALIGNED_WORDS = align(OCR_TEXT, UNALIGNED_WORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Varify Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def varify(text, aligned_words):\n",
    "    tpos = 0\n",
    "    for widx, (word, pos) in enumerate(aligned_words):\n",
    "        for wpos in range(len(word)):\n",
    "            while text[tpos].isspace():\n",
    "                tpos += 1\n",
    "            if not _match(word[wpos], text[tpos]):\n",
    "                if text[tpos:tpos + 2] == '-\\n' and ord(word[wpos]) == ord(text[tpos + 2]):\n",
    "                    tpos += 2\n",
    "                else:\n",
    "                    raise ValueError('Character mismatched: (%d) %s, (%d) %s\\nat %d:  %s\\nand: %s'\n",
    "                                     % (ord(word[wpos]), word[wpos + 1: wpos + 5],\n",
    "                                        ord(text[tpos]), text[tpos + 1: tpos + 5],\n",
    "                                        widx, str(aligned_words[widx - 2: widx + 3]),\n",
    "                                        text[tpos - 10: tpos + 10]\n",
    "                                       ))\n",
    "            tpos += 1\n",
    "\n",
    "# varify the fixed word\n",
    "varify(OCR_TEXT, ALIGNED_WORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Output Aligned Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _to_word_obj(words, i):\n",
    "    l = len(words)\n",
    "    return [words[i - 4][0] if i > 3 else '',\n",
    "            words[i - 3][0] if i > 2 else '',\n",
    "            words[i - 2][0] if i > 1 else '',\n",
    "            words[i - 1][0] if i > 0 else '',\n",
    "            words[i][0],\n",
    "            words[i + 1][0] if i < l - 1 else '',\n",
    "            words[i + 2][0] if i < l - 2 else '',\n",
    "            words[i + 3][0] if i < l - 3 else '',\n",
    "            str(words[i][1])\n",
    "           ]\n",
    "    \n",
    "def to_word_objs(words):\n",
    "    return [_to_word_obj(words, i) for i in range(len(words))]\n",
    "\n",
    "WORDS_OBJS = to_word_objs(ALIGNED_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['(', 'Kent', ')', ',', '1906', ',', 'and', 'altogether', '497230'],\n",
       " ['Kent', ')', ',', '1906', ',', 'and', 'altogether', 'over', '497234'],\n",
       " [')', ',', '1906', ',', 'and', 'altogether', 'over', 'a', '497236'],\n",
       " [',', '1906', ',', 'and', 'altogether', 'over', 'a', 'score', '497240'],\n",
       " ['1906', ',', 'and', 'altogether', 'over', 'a', 'score', 'in', '497251'],\n",
       " [',', 'and', 'altogether', 'over', 'a', 'score', 'in', 'Sussex', '497256'],\n",
       " ['and', 'altogether', 'over', 'a', 'score', 'in', 'Sussex', '.', '497258'],\n",
       " ['altogether', 'over', 'a', 'score', 'in', 'Sussex', '.', '', '497264'],\n",
       " ['over', 'a', 'score', 'in', 'Sussex', '.', '', '', '497267'],\n",
       " ['a', 'score', 'in', 'Sussex', '.', '', '', '', '497273']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORDS_OBJS[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407369\n",
      "83132\n"
     ]
    }
   ],
   "source": [
    "for i, w in enumerate(WORDS_OBJS):\n",
    "    if int(w[-1]) > SPLIT_POS:\n",
    "        split_idx = i\n",
    "        break\n",
    "print(SPLIT_POS)\n",
    "print(split_idx)\n",
    "\n",
    "def write(word_objs, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        lines = ['\\t'.join(w) for w in word_objs]\n",
    "        file.write('\\n'.join(lines))\n",
    "        \n",
    "write(WORDS_OBJS[:split_idx], OUT_WORDS_TRAIN_PATH)\n",
    "write(WORDS_OBJS[split_idx:], OUT_WORDS_TEST_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "navigate_menu": false,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "1023px",
    "left": "0px",
    "right": "auto",
    "top": "43px",
    "width": "280px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
